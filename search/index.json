[{"content":" Resurrecting Ancient Proteins in Python | SciPy 2018   How Jupyter Makes Experimental and Computational Collaborations Easy | JupyterCon 2017   ","href":"/talks/","title":"Talks"},{"content":" Here, I share my thoughts on science, statistics, open-source, and more. I\u0026rsquo;m just a single data point—a sample size of one—so don\u0026rsquo;t take these thoughts too seriously\u0026hellip;I\u0026rsquo;m still gathering more data.\nIn the meantime, I hope you find this blog useful.\n—Zach\n ","href":"/","title":"Home"},{"content":"","href":"/jupyter/","title":"Jupyter"},{"content":"","href":"/other/","title":"Other"},{"content":"","href":"/science/","title":"Science"},{"content":"","href":"/software/","title":"Software"},{"content":" NxAltair is a small library I created last year to draw NetworkX graphs in Altair. Altair is a declarative Python API for creating interactive visualizations powered by Vega. NetworkX is a broadly used library for analyzing network data.\nNetworkX comes with a simple but powerful drawing API out-of-the-box. It\u0026rsquo;s built on Matplotlib and allows you to customize the drawing of nodes, edges, and labels separately. One major downside of using Matplotlib here is that the figure is static. To explore the data further, we would need to re-render the figure in a different configuration.\nInteractivity for Free NxAltair brings simple interactivity that is particularly useful for analyzing networks. I\u0026rsquo;ll demonstrate this with examples. Here is a simple NetworkX example using the draw_networkx function:\nimport networkx as nx # Generate a random graph G = nx.fast_gnp_random_graph(n=20, p=0.25) # Add store some random attributes on each node. for n in G.nodes(): G.nodes[n][\u0026#39;weight\u0026#39;] = np.random.randn() G.nodes[n][\u0026#39;name\u0026#39;] = np.random.randint(1000) G.nodes[n][\u0026#39;viable\u0026#39;] = np.random.choice([\u0026#39;yes\u0026#39;, \u0026#39;no\u0026#39;]) # Compute positions for viz. pos = nx.spring_layout(G) # Draw the graph using matplotlib chart = nx.draw_networkx(G, pos=pos) If we replace NetworkX\u0026rsquo;s draw method with NxAltair\u0026rsquo;s, we get an Altair chart. And calling .interactive() adds \u0026ldquo;pan and zoom\u0026rdquo;.\n# Import NxAltair import nx_altair as nxa # Swap nx with nxa. chart = nxa.draw_networkx(G, pos=pos) # Add pan and zoom! chart.interactive()  var spec = \"data/chart1.json\"; vegaEmbed('#vis', spec).then(function(result) { // Access the Vega view instance (https://vega.github.io/vega/docs/api/view/) as result.view }).catch(console.error);  This is already useful for network figures that are crowded by many nodes and edges. We can zoom on regions of interest. But the interactivity doesn\u0026rsquo;t stop there\u0026hellip;\nAltair-level interactivity Because NxAltair returns Altair charts, we can leverage most of the features inside of Altair. For example, we easily add tool-tips to label our nodes — hover over any node and quickly view its data:\n# Set the node_tooltip argument. chart = nxa.draw_networkx( G, pos=pos, node_tooltip=[\u0026#34;name\u0026#34;, \u0026#34;weight\u0026#34;, \u0026#34;viable\u0026#34;] ).interactive()  var spec = \"data/chart2.json\"; vegaEmbed('#vis2', spec).then(function(result) { // Access the Vega view instance (https://vega.github.io/vega/docs/api/view/) as result.view }).catch(console.error);  NxAltair also has a feature not available in NetworkX. It can style the visualization using node and edge attributes. The values of those attributes are mapped onto properties of the visualization. For example, here we use the nodes \u0026ldquo;weight\u0026rdquo; attribute to color the nodes:\nchart = nxa.draw_networkx( G=G, pos=pos, node_size=200, node_color=\u0026#39;weight\u0026#39;, cmap=\u0026#39;viridis\u0026#39;, width=\u0026#39;weight\u0026#39;, ).interactive()  var spec = \"data/chart3.json\"; vegaEmbed('#vis3', spec).then(function(result) { // Access the Vega view instance (https://vega.github.io/vega/docs/api/view/) as result.view }).catch(console.error);  This is particularly handy in XX. ```python # Draw a basic chart chart = nxa.draw_networkx( G, pos=pos, ) # Get the node layer edges = chart.layer[0] nodes = chart.layer[1] # Build a brush brush = alt.selection_interval(encodings=['x', 'y']) color = alt.Color('viable:N', legend=None) # Condition nodes based on brush nodes = nodes.encode( fill=alt.condition(brush, color, alt.value('gray')), ).add_selection( brush ) # Create a bar graph to show highlighted nodes. bars = alt.Chart(nodes.data).mark_bar().encode( x=alt.X('count()', scale=alt.Scale(domain=(0,20))), y='viable', color='viable', ).transform_filter( brush ) alt.vconcat(edges+nodes, bars) ```  var spec = \"data/chart4.json\"; vegaEmbed('#vis4', spec).then(function(result) { // Access the Vega view instance (https://vega.github.io/vega/docs/api/view/) as result.view }).catch(console.error);  API Design (may delete) I followed three requirements when building NXAltair:\n Build an API that\u0026rsquo;s as close to NetworkX as possible Return Altair Charts that can be easily customized using Altair\u0026rsquo;s API. Allow users to declare attributes as visual features.  Conclusion ","href":"/software/nx_altair/","title":"NetworkX meets Altair"},{"content":"Here\u0026rsquo;s something I’m learning as I attempt to write more often…\n There’s a lot of “not writing” that happens in the early stages of writing.\n While that’s probably obvious to more seasoned writers, it’s something I’m just now realizing has been a road block for me.\nIt takes time to formulate thoughts, reason through ideas, articulate concepts and put them down on a page. As a result, that page stays blank for a long time (or gets littered with useless fragments).\nIt’s really easy to perceive those early phases as wasted time. I mean, there’s no measurable or tangible output, right? I often have to remind myself, it’s not wasted time. Writing is a process, and the early phases usually require unrecorded thinking. The time spent thinking, though, leads to progress in writing later. If I let myself get discouraged by the lack words on the page, I’ll procrastinate writing further.\nInstead, go through that phase—put in the time thinking. Don\u0026rsquo;t measure progress by the number of words. Otherwise, the page will never get filled.\n","href":"/other/writing/","title":"\"Not writing\" is still writing."},{"content":" Pandas is Python\u0026rsquo;s DataFrame library. There are many reasons why should be using DataFrame\u0026rsquo;s in your data science workflow, but I\u0026rsquo;ll have to leave that for another post. Here, I\u0026rsquo;ll show you how to tailor Pandas to your business, research, or personal workflow using Pandas\u0026rsquo; extension API.\nIn versions 0.24.x, Pandas introduced a new API for extending Pandas. This API handled the boilerplate code for registering custom accessors onto Pandas objects. (an accessor is an object attached to a DataFrame/Series that can access and \u0026ldquo;mutate\u0026rdquo; that DataFrame/Series). Specifically, it included two Python decorators:\n register_dataframe_accessor() register_series_accessor().  Pandas-flavor is a library that backports this API to earlier versions of Pandas. I recommend using Pandas-flavor when writing custom accessors, since many users probably haven\u0026rsquo;t upgraded to Pandas 0.24.x yet. (Full disclosure\u0026mdash;I wrote Pandas-flavor)\nCustom Accessor Here\u0026rsquo;s how you write an accessor:\n Give your accessor a name. Pass this name as an argument to the register_dataframe_accessor. Create an accessor class, a Python object. The name of the class doesn\u0026rsquo;t matter. It must have an __init__() method and take the Pandas DataFrame/Series as an argument. Store the DataFrame/Series as a hidden attribute on the Accessor (prefix the attribute with an underscore); I suggest self._df. Add your methods and attributes as members of the Accessor class. You can access and mutate the dataframe by affecting the self._df attribute.  As an example, here\u0026rsquo;s a simple \u0026ldquo;finance\u0026rdquo; accessor that has a \u0026ldquo;get_losses\u0026rdquo; method:\n# pandas_finance.py module from pandas_flavor import register_dataframe_accessor @register_dataframe_accessor(\u0026#34;finance\u0026#34;) class FinanceAccessor: \u0026#34;\u0026#34;\u0026#34;Extra methods for finance dataframes.\u0026#34;\u0026#34;\u0026#34; def __init__(self, df): self._df = df def get_losses(self): # Slice out values less than 1. df = self._df losses = df[df[\u0026#34;gains_and_losses\u0026#34;] \u0026lt; 0] return losses Here\u0026rsquo;s what it would look like to use this accessor:\n# Import the pandas_finance module above import pandas import pandas_finance df = pandas.DataFrame({ \u0026#34;value\u0026#34;: [5, -5, 45, 65, 30], \u0026#34;gains_and_losses\u0026#34;: [5, -10, 50, 20, -35] }) df.finance.get_losses()  value gains_and_losses 1 -5 -10 4 30 -35  Custom Methods Besides this backport, Pandas-flavor adds another way to extend Pandas:\n register_dataframe_method() register_series_method()  These two decorators allow you to register custom methods directly onto Pandas\u0026rsquo; DataFrame/Series. We could adjust the example above to attach the \u0026ldquo;get_losses\u0026rdquo; method directly to the DataFrame.\n# pandas_finance.py module from pandas_flavor import register_dataframe_method @register_dataframe_method def get_losses(df): # Slice out values less than 1. losses = df[df[\u0026#34;gains_and_losses\u0026#34;] \u0026lt; 0] return losses To use this method:\n# Import the pandas_finance module above import pandas import pandas_finance df = pandas.DataFrame({ \u0026#34;value\u0026#34;: [5, -5, 45, 65, 30], \u0026#34;gains_and_losses\u0026#34;: [5, -10, 50, 20, -35] }) df.get_losses()  value gains_and_losses 1 -5 -10 4 30 -35  (It is likely that Pandas deliberately chose not implement \u0026ldquo;method registration\u0026rdquo;. If everyone starts monkeypatching DataFrames with custom methods, it could lead to confusion in the Pandas community. The preferred Pandas approach is to namespace your methods by registering an accessor that contains your custom methods.)\nInstalling Pandas-flavor Try out Pandas-flavor and let me know what you think!\nYou can install Pandas-flavor with pip:\npip install pandas-flavor  or conda:\nconda install -c conda-forge pandas-flavor  Extensions in the wild Here is a non-exhaustive list of libraries that use Pandas\u0026rsquo; (and Pandas-flavor\u0026rsquo;s) new extension API:\n GeoPandas: Pandas for geographic data and information. PhyloPandas: the Pandas DataFrame for phylogenetics. Pdvega: Vega-lite plots from Pandas DataFrames. pyjanitor: data \u0026ldquo;cleaning\u0026rdquo; API for Pandas DataFrames. python-ctd: tools to load hydrographic data into Pandas DataFrames. Pandas\u0026rsquo; plot API: yes, this is part of Pandas\u0026rsquo; core library, but acts like an extension.  ","href":"/software/pandas-flavor/","title":"Writing your own flavor of Pandas"},{"content":"Recently, there has been a lot of discussion on whether the hype around Jupyter Notebooks is deserved.\nCritics say that Notebooks are bad for software development. They actually encourage a lot of bad practices and confuse people who are learning to program. This is a fair criticism, and I mostly agree. (I recommend watching the talk, \u0026ldquo;I don\u0026rsquo;t like notebooks.\u0026rdquo; to hear some common criticisms).\nThe dominant counter argument I hear is\u0026ndash;\n The interactivity offered by Notebooks is a \u0026ldquo;net win\u0026rdquo;. New programmers can execute small bits of code and get instant feedback. Old programmers can prototype code more flexibly. Scientists can explore data freely.\n While all these things are true, I think we\u0026rsquo;re missing the biggest \u0026ldquo;win\u0026rdquo;.\nI am constantly surprised by the diversity of Jupyter\u0026rsquo;s users. I\u0026rsquo;ve met Jovyans from all different backgrounds: psychology, kinesiology, sociology, journalism, political science, engineering, chemistry, physics, biology, economics, medicine, aviation, \u0026hellip; the list goes on. What is it about Notebooks that attracts such a general audience?\nI believe it\u0026rsquo;s because Jupyter Notebooks innovate how we communicate. They use a familiar interface\u0026mdash;a word-processor document\u0026mdash;and add to it interactive computation and visualization. If you\u0026rsquo;re not a programmer, \u0026ldquo;reading\u0026rdquo; a Jupyter Notebook doesn\u0026rsquo;t feel too foreign to you. The rendered markdown cells look like regular text. Math equations look like your college textbooks. The inline plots make the document look like science or news articles. Sure\u0026mdash;there\u0026rsquo;s some code in there. But, even the code is almost digestable. (Thanks, Python!)\nJupyter Notebooks can do many things that other literary mediums cannot. They seamlessly integrate more rich elements with classic text\u0026mdash;weaving inline interactive plots, maps, data explorers, tables, dashboards, etc. Authors are no longer limited to the static nature of classic word processors; they can leverage interactivity and flexibility that\u0026rsquo;s only possible in computational documents. This allows authors to raise their level of communication to the height of innovation that notebooks offer.\nThis is why we need Jupyter Notebooks. They expand the world\u0026rsquo;s communication toolkit. I agree that Jupyter Notebooks may be not an ideal tool for software developers, but they are an innovative tool for story tellers.\n","href":"/jupyter/notebook-communication/","title":"Should Jupyter Notebooks go away?"},{"content":" \u0026ldquo;If you want to go fast, go alone. If you want to go far, go together.\u0026rdquo;\n A few weeks ago, I had the opportunity to join many members of the Project Jupyter\u0026rsquo;s core development team in Washington DC for our annual team meeting. A huge thank you to Dr. Lorena Barba for hosting our team at George Washington University for the week.\nThis was an incredible experience.\nI counted ~20 core contributors representing 9 different countries in the room. Both new and long-time contributors were present. Fernando Perez, the creator of IPython (in 2001) and co-creator of Project Jupyter, was there, as well as Leticia Portella, a new team member that joined through Outreachy four months earlier. The best part\u0026ndash;it did not matter what your background was; everyone had an voice.\nI won\u0026rsquo;t spend much time talking about the specific things we discussed during the week (you can find more detail in the links at the bottom). I will just say\u0026ndash;I was amazed by how many times phrases like \u0026ldquo;empower everyone\u0026rdquo; and \u0026ldquo;for the greater good\u0026rdquo; were mentioned thoughout the week.\nThere\u0026rsquo;s one thing that is certain; the Jupyter team cares deeply for its community.\nMost of our conversations were centered around one question: how do we build a governance model that scales and protects Project Jupyter\u0026rsquo;s community?\nThe Jupyter ecosystem is a global community; that comes with many challenges. Until now, Jupyter has suffered from the \u0026ldquo;tyranny of structurelessness\u0026rdquo;. But as Jupyter finds itself pulled by various, major stake-holders like IBM, Netflix, Amazon, Microsoft, Google, etc., the community will need to invest time and energy into establishing a structure that protects and sustains its members. During our week together, we constructed some actionable next steps. Now, we just need to make them happen. To follow things that are happening around Jupyter, I strongly recommend you check out our Discourse page.\nFurther reading I recommend from this week:\n Chris Holdgraf\u0026rsquo;s thoughts: https://predictablynoisy.com/jupyter-team-meeting-2019 Jupyter Discourse thread: https://discourse.jupyter.org/t/2019-in-person-team-meeting-updates-and-notes/458  ","href":"/jupyter/jupyter-team-meeting/","title":"Jupyter Team Meeting 2019"},{"content":"Finally starting a blog. Thank you to Leticia Portella and Saul Shanabrook for pushing to make it happened.\nI\u0026rsquo;m planning to use this site to share three major types of content.\n I\u0026rsquo;ll announce software that I\u0026rsquo;ve published or review software someone else published.\n I\u0026rsquo;ll highlight things I come across in basic science and research domains. Since my background is in science, I\u0026rsquo;ll use this blog to stay connected to that community.\n I\u0026rsquo;ll try to record useful tricks, hints, and details I found useful in my own pursuit to be a better developer. There is nothing more frustrating than the scenario so accurately depicted in Randall Monroe\u0026rsquo;s XKCD comic:\n\n  ","href":"/other/first-post/","title":"Hello, world."},{"content":"","href":"/authors/","title":"Authors"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/page/","title":"Pages"},{"content":"","href":"/search/","title":"Search"},{"content":"","href":"/series/","title":"Series"},{"content":"","href":"/tags/","title":"Tags"},{"content":"","href":"/tags/altair/","title":"altair"},{"content":"","href":"/tags/jupyter/","title":"jupyter"},{"content":"","href":"/tags/networkx/","title":"networkx"},{"content":"","href":"/tags/notebooks/","title":"notebooks"},{"content":"","href":"/tags/open-source-community/","title":"open-source community"},{"content":"","href":"/tags/pandas/","title":"pandas"},{"content":"","href":"/tags/python/","title":"python"},{"content":"","href":"/tags/software/","title":"software"},{"content":"","href":"/tags/writing/","title":"writing"},{"content":"","href":"/tags/xkcd/","title":"xkcd"},{"content":"","href":"/authors/zsailer/","title":"zsailer"}]
